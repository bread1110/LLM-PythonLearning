"""
å‹å‹•åŸºæº–æ³•RAGæŸ¥è©¢æ¸¬è©¦å·¥å…· - ç°¡åŒ–ç‰ˆæœ¬
åªä½¿ç”¨å‘é‡æœç´¢ + å¼·åŠ›ç¹é«”ä¸­æ–‡Rerankeræ¨¡å‹
"""

import os
import json
import psycopg2
from psycopg2.extras import RealDictCursor
from typing import List, Dict, Any, Callable
import numpy as np
from datetime import datetime
from dotenv import load_dotenv
from tavily import TavilyClient
from utils.database_config import get_database_config
from utils.ai_client import get_embedding_for_content, chat_with_azure_openai
from sentence_transformers import CrossEncoder
import concurrent.futures
import time

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

tavily_client = TavilyClient(api_key=os.getenv("TAVILY_API_KEY"))

class ChineseReranker:
    """ç¹é«”ä¸­æ–‡å°ˆç”¨ Reranker æ¨¡å‹"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç¹é«”ä¸­æ–‡Rerankeræ¨¡å‹"""
        self.model = None
        
        # ä½¿ç”¨BAAIçš„BGE Reranker base - å¹³è¡¡é€Ÿåº¦èˆ‡è³ªé‡ï¼Œæ”¯æ´ç¹é«”ä¸­æ–‡
        model_config = {
            'name': 'bge-reranker-base',
            'model_path': 'BAAI/bge-reranker-base'
        }
        
        try:
            print(f"ğŸ”§ æ­£åœ¨åŠ è¼‰ {model_config['name']} ç¹é«”ä¸­æ–‡Rerankeræ¨¡å‹...")
            self.model = CrossEncoder(model_config['model_path'])
            print(f"âœ… {model_config['name']} æ¨¡å‹åŠ è¼‰æˆåŠŸ")
        except Exception as e:
            print(f"âŒ {model_config['name']} æ¨¡å‹åŠ è¼‰å¤±æ•—: {e}")
            print("ğŸ”„ å˜—è©¦å‚™ç”¨æ¨¡å‹...")
            try:
                # å‚™ç”¨æ¨¡å‹1ï¼šæ›´å°çš„BGEæ¨¡å‹
                print("ğŸ”§ å˜—è©¦åŠ è¼‰ bge-reranker-base å‚™ç”¨æ¨¡å‹...")
                self.model = CrossEncoder('BAAI/bge-reranker-base')
                print("âœ… BGE base å‚™ç”¨æ¨¡å‹åŠ è¼‰æˆåŠŸ")
            except Exception as e2:
                print(f"âŒ BGE å‚™ç”¨æ¨¡å‹åŠ è¼‰å¤±æ•—: {e2}")
                try:
                    # å‚™ç”¨æ¨¡å‹2ï¼šè¼•é‡ç´šæ¨¡å‹
                    print("ğŸ”§ å˜—è©¦åŠ è¼‰è¼•é‡ç´šå‚™ç”¨æ¨¡å‹...")
                    self.model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
                    print("âœ… è¼•é‡ç´šå‚™ç”¨æ¨¡å‹åŠ è¼‰æˆåŠŸ")
                except Exception as e3:
                    print(f"âŒ æ‰€æœ‰å‚™ç”¨æ¨¡å‹éƒ½ç„¡æ³•åŠ è¼‰: {e3}")
                    print("âš ï¸ å°‡ä½¿ç”¨ç„¡rerankæ¨¡å¼")
    
    def rerank(self, query: str, results: List[Dict], top_k: int = 5) -> List[Dict]:
        """ä½¿ç”¨ç¹é«”ä¸­æ–‡Rerankeré€²è¡Œæ’åº"""
        if not self.model or not results:
            return results[:top_k]
        
        print(f"ğŸ¯ ä½¿ç”¨ç¹é«”ä¸­æ–‡Rerankerå° {len(results)} å€‹çµæœé€²è¡Œé‡æ’åº...")
        
        # é–‹å§‹è¨ˆæ™‚
        start_time = time.time()
        
        try:
            # æº–å‚™æŸ¥è©¢-æ–‡æª”å°
            prep_start = time.time()
            query_doc_pairs = []
            for result in results:
                content = result.get('content', '')
                # é™åˆ¶æ–‡æœ¬é•·åº¦ä»¥æå‡æ€§èƒ½
                if len(content) > 512:
                    content = content[:512] + "..."
                query_doc_pairs.append([query, content])
            prep_time = time.time() - prep_start
            
            # ä½¿ç”¨æ¨¡å‹è©•åˆ†
            predict_start = time.time()
            scores = self.model.predict(query_doc_pairs)
            predict_time = time.time() - predict_start
            
            # æ·»åŠ rerankåˆ†æ•¸åˆ°çµæœä¸¦æ’åº
            sort_start = time.time()
            for i, result in enumerate(results):
                result['rerank_score'] = float(scores[i]) if i < len(scores) else 0.0
            
            # æ ¹æ“šrerankåˆ†æ•¸æ’åº
            sorted_results = sorted(results, key=lambda x: x.get('rerank_score', 0), reverse=True)
            top_results = sorted_results[:top_k]
            sort_time = time.time() - sort_start
            
            # ç¸½è¨ˆæ™‚
            total_time = time.time() - start_time
            
            print(f"âœ… Rerankerå®Œæˆï¼Œè¿”å›å‰ {len(top_results)} å€‹çµæœ")
            print(f"â±ï¸ Reranker è¨ˆæ™‚çµ±è¨ˆ:")
            print(f"   - æ•¸æ“šæº–å‚™: {prep_time:.3f}ç§’")
            print(f"   - æ¨¡å‹æ¨ç†: {predict_time:.3f}ç§’") 
            print(f"   - çµæœæ’åº: {sort_time:.3f}ç§’")
            print(f"   - ç¸½è™•ç†æ™‚é–“: {total_time:.3f}ç§’")
            print(f"   - å¹³å‡æ¯å€‹çµæœ: {total_time/len(results):.4f}ç§’")
            
            self._display_results(top_results)
            
            return top_results
            
        except Exception as e:
            total_time = time.time() - start_time
            print(f"âŒ Rerankerå¤±æ•—: {e} (è€—æ™‚: {total_time:.3f}ç§’)")
            return results[:top_k]
    
    def _display_results(self, results: List[Dict]):
        """é¡¯ç¤ºrerankçµæœæ‘˜è¦"""
        print("ğŸ“Š Rerankerçµæœæ‘˜è¦:")
        for i, result in enumerate(results, 1):
            rerank_score = result.get('rerank_score', 0)
            print(f"  {i}. ID:{result.get('id', 'N/A')} | Rerankåˆ†æ•¸:{rerank_score:.4f}")

class LaborLawAgent:
    """å‹å‹•åŸºæº–æ³• AI Agent ç³»çµ± - ç°¡åŒ–ç‰ˆ"""
    
    def __init__(self):
        """åˆå§‹åŒ– AI Agent ç³»çµ±"""
        # PostgreSQLé€£æ¥é…ç½®
        self.db_config = get_database_config()
        
        # åˆå§‹åŒ–ç¹é«”ä¸­æ–‡ Reranker ç³»çµ±
        print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–ç¹é«”ä¸­æ–‡ Reranker ç³»çµ±...")
        self.reranker = ChineseReranker()
        
        # åˆå§‹åŒ–å·¥å…·ç³»çµ±
        self._setup_tools()
    
    def _setup_tools(self):
        """è¨­ç½®å¯ç”¨çš„å·¥å…·å’Œå‡½æ•¸å®šç¾©"""
        self.tools = {
            "web_search": {
                "function": self._tool_web_search,
                "description": "ä½¿ç”¨ç¶²è·¯æœç´¢ç²å–æœ€æ–°çš„æ³•å¾‹è³‡è¨Šã€ç›¸é—œæ–°èæˆ–å…¶ä»–è£œå……è³‡æ–™",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "æœç´¢æŸ¥è©¢ï¼Œç”¨æ–¼åœ¨ç¶²è·¯ä¸Šæœç´¢ç›¸é—œè³‡è¨Š"
                        },
                        "max_results": {
                            "type": "integer",
                            "description": "è¿”å›çµæœæ•¸é‡é™åˆ¶ï¼Œé»˜èªç‚º5",
                            "default": 5
                        }
                    },
                    "required": ["query"]
                }
            },
            "vector_search": {
                "function": self._tool_vector_search,
                "description": "ä½¿ç”¨èªç¾©å‘é‡æœç´¢æŸ¥æ‰¾ç›¸é—œçš„å‹å‹•åŸºæº–æ³•æ¢æ–‡å’Œè¦å®šï¼Œè‡ªå‹•ä½¿ç”¨ç¹é«”ä¸­æ–‡Rerankeræ¨¡å‹é‡æ–°æ’åºçµæœ",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "è‡ªç„¶èªè¨€æŸ¥è©¢ï¼Œæè¿°æ‚¨æƒ³äº†è§£çš„å‹åŸºæ³•ç›¸é—œå•é¡Œ"
                        },
                        "limit": {
                            "type": "integer",
                            "description": "è¿”å›çµæœæ•¸é‡ï¼Œé»˜èªç‚º15",
                            "default": 15
                        }
                    },
                    "required": ["query"]
                }
            }
        }
        
        # è½‰æ›ç‚º OpenAI function calling æ ¼å¼
        self.tool_definitions = []
        for name, tool in self.tools.items():
            self.tool_definitions.append({
                "type": "function",
                "function": {
                    "name": name,
                    "description": tool["description"],
                    "parameters": tool["parameters"]
                }
            })
    
    def _tool_vector_search(self, query: str, limit: int = 15) -> Dict[str, Any]:
        """å·¥å…·ï¼šå‘é‡æœç´¢ + ç¹é«”ä¸­æ–‡Reranker"""
        print(f"ğŸ” åŸ·è¡Œå‘é‡æœç´¢: '{query}'")
        
        # ç”ŸæˆæŸ¥è©¢embedding
        query_embedding = self.query_aoai_embedding(query)
        if not query_embedding:
            return {"error": "ç„¡æ³•ç”ŸæˆæŸ¥è©¢embedding"}
        
        try:
            conn = psycopg2.connect(**self.db_config)
            cur = conn.cursor(cursor_factory=RealDictCursor)
            
            # å‘é‡æœç´¢SQL
            search_sql = """
            SELECT 
                id,
                content,
                created_at,
                cosine_similarity(embedding_vector, %s::double precision[]) as similarity,
                length(content) as char_count
            FROM embeddings
            WHERE embedding_vector IS NOT NULL
            ORDER BY similarity DESC
            LIMIT %s;
            """
            
            cur.execute(search_sql, (query_embedding, limit))
            results = cur.fetchall()
            
            cur.close()
            conn.close()
            
            search_results = [dict(row) for row in results]
            print(f"âœ… æ‰¾åˆ° {len(search_results)} å€‹ç›¸é—œçµæœ")
            
            # ä½¿ç”¨ç¹é«”ä¸­æ–‡ Reranker é€²è¡Œé‡æ’åº
            if search_results:
                print(f"ğŸ”„ å° {len(search_results)} å€‹çµæœé€²è¡Œç¹é«”ä¸­æ–‡Rerankeræ’åº...")
                
                reranked_results = self.reranker.rerank(query, search_results, top_k=5)
                
                print(f"âœ… ç¹é«”ä¸­æ–‡Rerankerå®Œæˆï¼Œæœ€çµ‚è¿”å› {len(reranked_results)} å€‹çµæœ")
                
                return {
                    "success": True,
                    "results": reranked_results,
                    "count": len(reranked_results),
                    "original_count": len(search_results),
                    "reranked": True,
                    "reranking_method": "chinese_reranker"
                }
            else:
                return {
                    "success": True,
                    "results": search_results,
                    "count": len(search_results),
                    "reranked": False
                }
            
        except Exception as e:
            error_msg = f"å‘é‡æœç´¢æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}"
            print(f"âŒ {error_msg}")
            return {"error": error_msg}

    def _tool_web_search(self, query: str, max_results: int = 5) -> Dict[str, Any]:
        """å·¥å…·ï¼šç¶²è·¯æœç´¢"""
        print(f"ğŸŒ åŸ·è¡Œç¶²è·¯æœç´¢: '{query}'")
        
        try:
            # ä½¿ç”¨ Tavily å®¢æˆ¶ç«¯é€²è¡Œæœç´¢
            search_result = tavily_client.search(query, max_results=max_results)
            
            # æå–æœ‰ç”¨çš„æœç´¢çµæœ
            if search_result and 'results' in search_result:
                results = []
                for item in search_result['results']:
                    result_item = {
                        'title': item.get('title', ''),
                        'content': item.get('content', ''),
                        'url': item.get('url', ''),
                        'score': item.get('score', 0)
                    }
                    results.append(result_item)
                
                print(f"âœ… ç¶²è·¯æœç´¢æ‰¾åˆ° {len(results)} å€‹çµæœ")
                
                return {
                    "success": True,
                    "results": results,
                    "count": len(results),
                    "query": query
                }
            else:
                return {"error": "ç¶²è·¯æœç´¢æœªè¿”å›æœ‰æ•ˆçµæœ"}
                
        except Exception as e:
            error_msg = f"ç¶²è·¯æœç´¢æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}"
            print(f"âŒ {error_msg}")
            return {"error": error_msg}

    def chat_with_aoai_gpt(self, messages: List[Dict], tools: List[Dict] = None) -> tuple:
        """èˆ‡ Azure OpenAI GPT é€²è¡Œå°è©±"""
        return chat_with_azure_openai(messages, tools)

    def query_aoai_embedding(self, content: str) -> list[float]:
        """å¾ Azure OpenAI æœå‹™ç²å–æ–‡æœ¬çš„ embedding å‘é‡"""
        return get_embedding_for_content(content)
    
    def execute_tool(self, tool_name: str, **kwargs) -> Dict[str, Any]:
        """åŸ·è¡ŒæŒ‡å®šçš„å·¥å…·"""
        if tool_name not in self.tools:
            return {"error": f"æœªçŸ¥çš„å·¥å…·: {tool_name}"}
        
        try:
            tool_function = self.tools[tool_name]["function"]
            return tool_function(**kwargs)
        except Exception as e:
            return {"error": f"å·¥å…·åŸ·è¡Œå¤±æ•—: {e}"}
    
    def execute_tools_concurrently(self, tool_calls: List) -> List[Dict[str, Any]]:
        """ä¸¦è¡ŒåŸ·è¡Œå¤šå€‹å·¥å…·ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
        print(f"ğŸš€ é–‹å§‹ä¸¦è¡ŒåŸ·è¡Œ {len(tool_calls)} å€‹å·¥å…·...")
        
        # ä½¿ç”¨ ThreadPoolExecutor ä¾†ä¸¦è¡ŒåŸ·è¡Œå·¥å…·
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            # æº–å‚™ä»»å‹™
            futures = []
            for tool_call in tool_calls:
                function_name = tool_call.function.name
                function_args = json.loads(tool_call.function.arguments)
                
                # æäº¤ä»»å‹™åˆ°åŸ·è¡Œå™¨
                future = executor.submit(self.execute_tool, function_name, **function_args)
                futures.append((tool_call, future))
                
                print(f"ğŸ“‹ å·²æäº¤å·¥å…·ä»»å‹™: {function_name} åƒæ•¸: {function_args}")
            
            # ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆä¸¦æ”¶é›†çµæœ
            results = []
            for tool_call, future in futures:
                try:
                    result = future.result(timeout=60)  # 60ç§’è¶…æ™‚
                    results.append({
                        'tool_call': tool_call,
                        'result': result,
                        'success': True
                    })
                    print(f"âœ… å·¥å…· {tool_call.function.name} åŸ·è¡Œå®Œæˆ")
                except concurrent.futures.TimeoutError:
                    error_result = {"error": f"å·¥å…· {tool_call.function.name} åŸ·è¡Œè¶…æ™‚"}
                    results.append({
                        'tool_call': tool_call,
                        'result': error_result,
                        'success': False
                    })
                    print(f"â±ï¸ å·¥å…· {tool_call.function.name} åŸ·è¡Œè¶…æ™‚")
                except Exception as e:
                    error_result = {"error": f"å·¥å…·åŸ·è¡Œç•°å¸¸: {e}"}
                    results.append({
                        'tool_call': tool_call,
                        'result': error_result,
                        'success': False
                    })
                    print(f"âŒ å·¥å…· {tool_call.function.name} åŸ·è¡Œå¤±æ•—: {e}")
            
            print(f"ğŸ¯ æ‰€æœ‰å·¥å…·åŸ·è¡Œå®Œæˆï¼ŒæˆåŠŸ: {sum(1 for r in results if r['success'])}/{len(results)}")
            return results

    def rewrite_query(self, user_question: str) -> str:
        """æ”¹å¯«å’Œå®Œå–„ç”¨æˆ¶æŸ¥è©¢"""
        rewrite_messages = [
            {
                "role": "system", 
                "content": """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æŸ¥è©¢æ”¹å¯«å°ˆå®¶ã€‚è«‹å°‡ç”¨æˆ¶çš„å•é¡Œæ”¹å¯«æˆæ›´é©åˆæœç´¢çš„å®Œæ•´æŸ¥è©¢ã€‚

æ”¹å¯«åŸå‰‡ï¼š
1. ä¿æŒåŸæ„ä¸è®Š
2. è£œå……ç›¸é—œçš„æ³•å¾‹è¡“èª
3. ä½¿æŸ¥è©¢æ›´å…·é«”å’Œæº–ç¢º
4. é©åˆå‘é‡æœç´¢å’Œèªç¾©ç†è§£

ç¯„ä¾‹ï¼š
ç”¨æˆ¶å•é¡Œï¼šã€ŒåŠ ç­è²»æ€éº¼ç®—ï¼Ÿã€
æ”¹å¯«çµæœï¼šã€Œå‹å‹•åŸºæº–æ³•åŠ ç­è²»è¨ˆç®—æ–¹å¼ å¹³æ—¥å»¶é•·å·¥æ™‚è²»ç‡ å‡æ—¥å·¥ä½œå ±é…¬æ¨™æº–ã€

è«‹åªè¿”å›æ”¹å¯«å¾Œçš„æŸ¥è©¢ï¼Œä¸è¦åŒ…å«å…¶ä»–èªªæ˜ã€‚"""
            },
            {"role": "user", "content": f"è«‹æ”¹å¯«é€™å€‹å•é¡Œï¼š{user_question}"}
        ]
        
        try:
            message, _, _ = self.chat_with_aoai_gpt(rewrite_messages)
            improved_query = message.content.strip() if message.content else user_question
            print(f"ğŸ“ æŸ¥è©¢æ”¹å¯«: '{user_question}' â†’ '{improved_query}'")
            return improved_query
        except Exception as e:
            print(f"âš ï¸ æŸ¥è©¢æ”¹å¯«å¤±æ•—: {e}")
            return user_question

    def generate_agent_response(self, user_question: str, conversation_history: List[Dict[str, str]] = None) -> str:
        """ç”Ÿæˆ AI Agent å›æ‡‰"""
        print(f"ğŸ¤– AI Agent é–‹å§‹è™•ç†å•é¡Œ: '{user_question}'")
        
        # æ­¥é©Ÿ1ï¼šæ”¹å¯«å’Œå®Œå–„æŸ¥è©¢
        print("\nğŸ“ æ­¥é©Ÿ1: æŸ¥è©¢æ”¹å¯«èˆ‡å®Œå–„")
        improved_query = self.rewrite_query(user_question)
        
        # æ§‹å»ºsystem prompt
        system_prompt = """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„å‹å‹•åŸºæº–æ³• AI åŠ©æ‰‹ã€‚ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ä¾†å›ç­”ç”¨æˆ¶å•é¡Œï¼š

1. vector_search - å‘é‡æœç´¢åŠŸèƒ½ï¼ˆä¸»è¦å·¥å…·ï¼‰ï¼š
   - ä½¿ç”¨èªç¾©ç†è§£æŸ¥æ‰¾ç›¸é—œçš„æ³•æ¢å’Œè¦å®š
   - è‡ªå‹•ä½¿ç”¨ç¹é«”ä¸­æ–‡Rerankeræ¨¡å‹é‡æ–°æ’åºçµæœ
   - é©ç”¨æ–¼æ‰€æœ‰æ³•æ¢ç›¸é—œæŸ¥è©¢
   
2. web_search - ç¶²è·¯æœç´¢åŠŸèƒ½ï¼š
   - ä½¿ç”¨ç¶²è·¯æœç´¢ç²å–æœ€æ–°çš„æ³•å¾‹è³‡è¨Š
   - æŸ¥æ‰¾ç›¸é—œæ–°èã€æ”¿ç­–è§£é‡‹ã€å¯¦å‹™æ¡ˆä¾‹

å›ç­”è¦æ±‚ï¼š
1. å„ªå…ˆä½¿ç”¨vector_searchæŸ¥æ‰¾æ³•æ¢ä¾æ“š
2. å¦‚éœ€è¦æœ€æ–°è³‡è¨Šæ‰ä½¿ç”¨web_search
3. å›ç­”è¦æº–ç¢ºã€å°ˆæ¥­ã€æ˜“æ‡‚
4. å¼•ç”¨å…·é«”æ³•æ¢æ¢æ–‡
5. æä¾›å¯¦å‹™å»ºè­°
6. æ ¹æ“šå°è©±æ­·å²æä¾›é€£è²«çš„å›ç­”"""

        # åˆå§‹åŒ–å°è©±
        messages = [{"role": "system", "content": system_prompt}]
        
        # åŠ å…¥å°è©±æ­·å²
        if conversation_history:
            print(f"ğŸ“š è¼‰å…¥ {len(conversation_history)} æ¢å°è©±æ­·å²")
            for msg in conversation_history:
                if msg.get("role") in ["user", "assistant"]:
                    messages.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })
        
        # åŠ å…¥ç•¶å‰å•é¡Œ
        messages.append({"role": "user", "content": improved_query})
        
        # AI Agent è¿­ä»£è™•ç†
        max_iterations = 5
        for iteration in range(max_iterations):
            print(f"\nğŸ”„ AI Agent è¿­ä»£ {iteration + 1}/{max_iterations}")
            
            try:
                # å‘¼å« GPT ä¸¦å‚³éå·¥å…·å®šç¾©
                message, input_tokens, output_tokens = self.chat_with_aoai_gpt(
                    messages, 
                    self.tool_definitions
                )
                
                print(f"ğŸ“Š Tokenä½¿ç”¨: è¼¸å…¥={input_tokens}, è¼¸å‡º={output_tokens}")
                
                # æ·»åŠ åŠ©æ‰‹å›æ‡‰åˆ°å°è©±æ­·å²
                messages.append({
                    "role": "assistant",
                    "content": message.content,
                    "tool_calls": [tool_call.__dict__ if hasattr(tool_call, '__dict__') else tool_call 
                                 for tool_call in message.tool_calls] if message.tool_calls else None
                })
                
                # æª¢æŸ¥æ˜¯å¦éœ€è¦åŸ·è¡Œå·¥å…·
                if message.tool_calls:
                    print(f"ğŸ”§ éœ€è¦åŸ·è¡Œ {len(message.tool_calls)} å€‹å·¥å…·")
                    
                    if len(message.tool_calls) > 1:
                        # å¤šå€‹å·¥å…· - ä½¿ç”¨ä¸¦è¡ŒåŸ·è¡Œ
                        print("ğŸš€ æª¢æ¸¬åˆ°å¤šå€‹å·¥å…·ï¼Œä½¿ç”¨ä¸¦è¡ŒåŸ·è¡Œæ¨¡å¼...")
                        
                        # é‹è¡Œä¸¦è¡Œå·¥å…·åŸ·è¡Œ
                        tool_results = self.execute_tools_concurrently(message.tool_calls)
                        
                        # å°‡çµæœæ·»åŠ åˆ°å°è©±æ­·å²
                        for tool_result_info in tool_results:
                            tool_call = tool_result_info['tool_call']
                            tool_result = tool_result_info['result']
                            
                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_call.id,
                                "content": json.dumps(tool_result, ensure_ascii=False, default=str)
                            })
                    else:
                        # å–®å€‹å·¥å…· - ä½¿ç”¨å‚³çµ±é †åºåŸ·è¡Œ
                        print("ğŸ”§ å–®å€‹å·¥å…·ï¼Œä½¿ç”¨é †åºåŸ·è¡Œæ¨¡å¼...")
                        tool_call = message.tool_calls[0]
                        function_name = tool_call.function.name
                        function_args = json.loads(tool_call.function.arguments)
                        
                        print(f"âš™ï¸ åŸ·è¡Œå·¥å…·: {function_name} åƒæ•¸: {function_args}")
                        
                        # åŸ·è¡Œå·¥å…·
                        tool_result = self.execute_tool(function_name, **function_args)
                        
                        # æ·»åŠ å·¥å…·çµæœåˆ°å°è©±
                        messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "content": json.dumps(tool_result, ensure_ascii=False, default=str)
                        })
                        
                        print(f"âœ… å·¥å…· {function_name} åŸ·è¡Œå®Œæˆ")
                else:
                    # æ²’æœ‰å·¥å…·èª¿ç”¨ï¼Œè¿”å›æœ€çµ‚å›ç­”
                    if message.content:
                        print(f"ğŸ¯ AI Agent å®Œæˆå›ç­”")
                        return message.content
                    
            except Exception as e:
                error_msg = f"AI Agent è™•ç†éŒ¯èª¤: {e}"
                print(f"âŒ {error_msg}")
                return f"æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{error_msg}"
        
        return "æŠ±æ­‰ï¼ŒAI Agent é”åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•¸ï¼Œç„¡æ³•å®Œæˆå›ç­”ã€‚"
    
    def display_llm_response(self, llm_response: str):
        """é¡¯ç¤ºLLMç”Ÿæˆçš„å›ç­”"""
        if llm_response:
            print("\n" + "="*60)
            print("ğŸ¤– AI Agent å›ç­”:")
            print("="*60)
            print(llm_response)
            print("="*60)
        else:
            print("âŒ æœªç²å¾—æœ‰æ•ˆå›ç­”")

def main():
    """ä¸»ç¨‹åº"""
    print("ğŸš€ å‹å‹•åŸºæº–æ³• AI Agent ç³»çµ± (ç°¡åŒ–ç‰ˆ) å•Ÿå‹•ä¸­...")
    
    try:
        # åˆå§‹åŒ– AI Agent
        agent = LaborLawAgent()
        print("âœ… ç³»çµ±åˆå§‹åŒ–å®Œæˆ")
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘å¿…è¦çš„ Python å¥—ä»¶: {e}")
        print("ğŸ’¡ è«‹åŸ·è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£æ‰€éœ€å¥—ä»¶:")
        print("   pip install sentence-transformers")
        return
    except Exception as e:
        print(f"âŒ ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
        print("ğŸ’¡ è«‹æª¢æŸ¥ç’°å¢ƒè®Šæ•¸è¨­å®šå’Œè³‡æ–™åº«é€£æ¥")
        return
    
    while True:
        print("\n" + "="*60)
        print("ğŸ¯ AI Agent æŸ¥è©¢ç³»çµ± (å‘é‡æœç´¢ + ç¹é«”ä¸­æ–‡Reranker)")
        print("ğŸ’¡ æ‚¨å¯ä»¥è©¢å•ä»»ä½•é—œæ–¼å‹å‹•åŸºæº–æ³•çš„å•é¡Œ")
        print("ğŸ“š æ³•æ¢æŸ¥è©¢ï¼šå·¥æ™‚è¦å®šã€åŠ ç­è²»è¨ˆç®—ã€è³‡é£ç›¸é—œæ³•æ¢ç­‰")
        print("ğŸ¯ ç‰¹è‰²åŠŸèƒ½ï¼šèªç¾©å‘é‡æœç´¢ + ç¹é«”ä¸­æ–‡Rerankeræ’åº")
        print("ğŸŒ ç¶²è·¯æœç´¢ï¼šæœ€æ–°ä¿®æ³•å‹•æ…‹ã€æ”¿ç­–è§£é‡‹ã€å¯¦å‹™æ¡ˆä¾‹ç­‰")
        print()
        print("è¼¸å…¥ 'exit' ä»¥é€€å‡ºç¨‹å¼")
        print("=" * 60)
        
        query = input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ: ").strip()
        if query.lower() == 'exit':
            print("æ„Ÿè¬ä½¿ç”¨å‹å‹•åŸºæº–æ³• AI Agent ç³»çµ±ï¼å†è¦‹ï¼")
            break
        
        if query:
            print("\nğŸš€ AI Agent é–‹å§‹è™•ç†æ‚¨çš„å•é¡Œ...")
            print("-" * 40)
            
            try:
                response = agent.generate_agent_response(query)
                agent.display_llm_response(response)
            except Exception as e:
                print(f"âŒ è™•ç†å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                print("ğŸ’¡ å»ºè­°ï¼šè«‹é‡æ–°è¡¨è¿°æ‚¨çš„å•é¡Œæˆ–ç¨å¾Œå†è©¦")

if __name__ == "__main__":
    main()