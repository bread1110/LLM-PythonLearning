# å°å…¥å¿…è¦çš„å¥—ä»¶
import streamlit as st              # ç”¨æ–¼å»ºç«‹ç¶²é ä»‹é¢
import os                          # ç”¨æ–¼è™•ç†ç’°å¢ƒè®Šæ•¸
from openai import AzureOpenAI     # Azure OpenAI API å®¢æˆ¶ç«¯
from dotenv import load_dotenv     # ç”¨æ–¼è¼‰å…¥ç’°å¢ƒè®Šæ•¸
import time                        # ç”¨æ–¼æ¨¡æ“¬æ‰“å­—æ•ˆæœ

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# å¾ç’°å¢ƒè®Šæ•¸ä¸­ç²å– Azure OpenAI æœå‹™æ‰€éœ€çš„é…ç½®
aoai_key = os.getenv("AOAI_KEY")             # Azure OpenAI API é‡‘é‘°
aoai_url = os.getenv("AOAI_URL")             # Azure OpenAI æœå‹™ç«¯é» URL
aoai_model_version = os.getenv("AOAI_MODEL_VERSION")    # ä½¿ç”¨çš„æ¨¡å‹ç‰ˆæœ¬

# æª¢æŸ¥å¿…è¦çš„ç’°å¢ƒè®Šæ•¸æ˜¯å¦éƒ½å·²è¨­ç½®
if not all([aoai_key, aoai_url, aoai_model_version]):
    st.error("è«‹ç¢ºä¿ .env æª”æ¡ˆä¸­å·²è¨­å®š AOAI_KEY, AOAI_URL, å’Œ AOAI_MODEL_VERSION")
    st.stop()

def chat_with_aoai_gpt(messages: list[dict]) -> tuple[str, int, int]:
    """èˆ‡ Azure OpenAI æœå‹™äº’å‹•çš„æ ¸å¿ƒå‡½æ•¸
    
    Args:
        messages: åŒ…å«å°è©±æ­·å²çš„åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ æ˜¯åŒ…å« role å’Œ content çš„å­—å…¸
    
    Returns:
        tuple: åŒ…å«ä¸‰å€‹å…ƒç´ ï¼š
            - AIçš„å›æ‡‰å…§å®¹ (str)
            - è¼¸å…¥æ¶ˆæ¯çš„ token æ•¸é‡ (int)
            - è¼¸å‡ºå›æ‡‰çš„ token æ•¸é‡ (int)
    """
    error_time = 0     # è¨˜éŒ„é‡è©¦æ¬¡æ•¸
    temperature = 0.7  # æ§åˆ¶å›æ‡‰çš„å‰µé€ æ€§/éš¨æ©Ÿæ€§ï¼Œ0ç‚ºæœ€ä¿å®ˆï¼Œ1ç‚ºæœ€å‰µé€ æ€§
    
    while error_time <= 2:  # æœ€å¤šé‡è©¦3æ¬¡
        error_time += 1
        try:
            # åˆå§‹åŒ– Azure OpenAI å®¢æˆ¶ç«¯
            client = AzureOpenAI(
                api_key=aoai_key,
                azure_endpoint=aoai_url,
            )

            # ç™¼é€è«‹æ±‚åˆ° Azure OpenAI æœå‹™
            aoai_response = client.chat.completions.create(
                model=aoai_model_version,
                messages=messages,
                temperature=temperature,
            )

            # æå– AI çš„å›æ‡‰
            assistant_message = aoai_response.choices[0].message.content

            # è¿”å› AI å›æ‡‰åŠç›¸é—œçš„ token ä½¿ç”¨çµ±è¨ˆ
            return (
                assistant_message,
                aoai_response.usage.prompt_tokens,
                aoai_response.usage.total_tokens - aoai_response.usage.prompt_tokens,
            )
        except Exception as e:
            print(f"éŒ¯èª¤ï¼š{str(e)}")
            return "", 0, 0  # ç™¼ç”ŸéŒ¯èª¤æ™‚è¿”å›ç©ºå€¼

# è¨­ç½®ç¶²é æ¨™é¡Œå’Œèªªæ˜
st.title("ğŸ’¬ æˆ‘çš„ç¬¬ä¸€å€‹ LLM Chatbot")
st.caption("ğŸš€ ä½¿ç”¨ Streamlit å’Œ LLM API å»ºç«‹")

# åˆå§‹åŒ–å°è©±æ­·å²
if "messages" not in st.session_state:
    # è¨­ç½®ç³»çµ±è§’è‰²çš„åˆå§‹æç¤º
    st.session_state.messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å‹å–„ä¸”æ¨‚æ–¼åŠ©äººçš„ AI åŠ©ç†ã€‚"}]
    print("Session state åˆå§‹åŒ–å®Œæˆ")

# é¡¯ç¤ºæ­·å²å°è©±å…§å®¹
for message in st.session_state.messages:
    if message["role"] != "system":  # ä¸é¡¯ç¤ºç³»çµ±æç¤º
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# è™•ç†ç”¨æˆ¶è¼¸å…¥
if prompt := st.chat_input("åœ¨é€™è£¡è¼¸å…¥ä½ çš„è¨Šæ¯..."):
    # å°‡ç”¨æˆ¶è¼¸å…¥æ·»åŠ åˆ°å°è©±æ­·å²
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    print(f"User: {prompt}")

    # é¡¯ç¤º AI åŠ©ç†çš„å›æ‡‰
    with st.chat_message("assistant"):
        message_placeholder = st.empty()  # å‰µå»ºç©ºç™½å®¹å™¨ç”¨æ–¼é¡¯ç¤ºå›æ‡‰
        message_placeholder.markdown("æ€è€ƒä¸­...")  # é¡¯ç¤ºè¼‰å…¥æç¤º

        # ç²å– AI çš„å›æ‡‰
        assistant_response, prompt_tokens, completion_tokens = chat_with_aoai_gpt(st.session_state.messages)

        # æ¨¡æ“¬æ‰“å­—æ•ˆæœé¡¯ç¤ºå›æ‡‰
        full_response = ""
        for chunk in assistant_response:
            full_response += chunk
            time.sleep(0.01)  # æ·»åŠ å»¶é²ä»¥å‰µé€ æ‰“å­—æ•ˆæœ
            message_placeholder.markdown(full_response + "â–Œ")  # é¡¯ç¤ºæ‰“å­—æ¸¸æ¨™
        message_placeholder.markdown(full_response)  # é¡¯ç¤ºå®Œæ•´å›æ‡‰

    # å°‡ AI çš„å›æ‡‰æ·»åŠ åˆ°å°è©±æ­·å²
    st.session_state.messages.append({"role": "assistant", "content": assistant_response})
    print(f"Assistant: {assistant_response}")

    # é‡æ–°åŠ è¼‰é é¢ä»¥æ›´æ–°å°è©±
    st.rerun()